Statistical relational learning (SRL) is a subdiscipline of artificial intelligence and machine learning that is concerned with domain models that exhibit both uncertainty (which can be dealt with using statistical methods) and complex, relational structure. Typically, the knowledge representation formalisms developed in SRL use (a subset of) first-order logic to describe relational properties of a domain in a general manner (universal quantification) and draw upon probabilistic graphical models (such as Bayesian networks or Markov networks) to model the uncertainty; some also build upon the methods of inductive logic programming. Significant contributions to the field have been made since the late 1990s.
As is evident from the characterization above, the field is not strictly limited to learning aspects; it is equally concerned with reasoning (specifically probabilistic inference) and knowledge representation. Therefore, alternative terms that reflect the main foci of the field include statistical relational learning and reasoning (emphasizing the importance of reasoning) and first-order probabilistic languages (emphasizing the key properties of the languages with which models are represented).


== Canonical tasks ==
A number of canonical tasks are associated with statistical relational learning, the most common ones being
collective classification, i.e. the (simultaneous) prediction of the class of several objects given objects' attributes and their relations
link prediction, i.e. predicting whether or not two or more objects are related
link-based clustering, i.e. the grouping of similar objects, where similarity is determined according to the links of an object, and the related task of collaborative filtering, i.e. the filtering for information that is relevant to an entity (where a piece of information is considered relevant to an entity if it is known to be relevant to a similar entity).
social network modelling
object identification/entity resolution/record linkage, i.e. the identification of equivalent entries in two or more separate databases/datasets


== Representation formalisms ==
One of the fundamental design goals of the representation formalisms developed in SRL is to abstract away from concrete entities and to represent instead general principles that are intended to be universally applicable. Since there are countless ways in which such principles can be represented, many representation formalisms have been proposed in recent years. In the following, some of the more common ones are listed in alphabetical order:
Bayesian logic program
BLOG model
Logic programs with annotated disjunctions
Markov logic networks
Multi-entity Bayesian network
Probabilistic relational model – a Probabilistic Relational Model (PRM) is the counterpart of a Bayesian network in statistical relational learning.
Probabilistic soft logic
Recursive random field
Relational Bayesian network
Relational dependency network
Relational Markov network
Relational Kalman filtering


== See also ==
Association rule learning
Formal concept analysis
Fuzzy logic
Grammar induction


== Resources ==
Lise Getoor and Ben Taskar: Introduction to statistical relational learning, MIT Press, 2007
Brian Milch, and Stuart J. Russell: First-Order Probabilistic Languages: Into the Unknown, Inductive Logic Programming, volume 4455 of Lecture Notes in Computer Science, page 10–24. Springer, 2006
Rodrigo de Salvo Braz, Eyal Amir, and Dan Roth: A Survey of First-Order Probabilistic Models, Innovations in Bayesian Networks, volume 156 of Studies in Computational Intelligence, Springer, 2008
Hassan Khosravi and Bahareh Bina: A Survey on Statistical Relational Learning, Advances in Artificial Intelligence, Lecture Notes in Computer Science, Volume 6085/2010, 256–268, Springer, 2010


== References ==