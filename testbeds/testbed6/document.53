  Algorithms, 4th edition 
     1.    Fundamentals 
       1.1    Programming Model 
       1.2    Data Abstraction 
       1.3    Stacks and Queues 
       1.4    Analysis of Algorithms 
       1.5    Case Study: Union-Find 
     2.    Sorting 
       2.1    Elementary Sorts 
       2.2    Mergesort 
       2.3    Quicksort 
       2.4    Priority Queues 
       2.5    Sorting Applications 
     3.    Searching 
       3.1    Symbol Tables 
       3.2    Binary Search Trees 
       3.3    Balanced Search Trees 
       3.4    Hash Tables 
       3.5    Searching Applications 
     4.    Graphs 
       4.1    Undirected Graphs 
       4.2    Directed Graphs 
       4.3    Minimum Spanning Trees 
       4.4    Shortest Paths 
     5.    Strings 
       5.1    String Sorts 
       5.2    Tries 
       5.3    Substring Search 
       5.4    Regular Expressions 
       5.5    Data Compression 
     6.    Context 
       6.1    Event-Driven Simulation 
       6.2    B-trees 
       6.3    Suffix Arrays 
       6.4    Maxflow 
       6.5    Reductions 
       6.6    Intractability 
   Related Booksites 
  Web Resources 
   FAQ 
   Data 
   Code 
   Errata 
   Cheatsheet 
   References 
   Online Course 
   Lecture Slides 
   Programming Assignments 
  (function() {
    var cx = '005649317310637734940:s7fqljvxwfs' 
    var gcse = document.createElement('script') 
    gcse.type = 'text/javascript' 
    gcse.async = true 
    gcse.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') +
        '//www.google.com/cse/cse.js?cx=' + cx 
    var s = document.getElementsByTagName('script')[0] 
    s.parentNode.insertBefore(gcse, s) 
  })() 
 3.4    Hash Tables 
  If keys are small integers, we can use an array to implement a symbol table, by interpreting the key as an array index so that we can store the value associated with key i in array position i. In this section, we consider hashing, an extension of this simple method that handles more complicated types of keys. We reference key-value pairs using arrays by doing arithmetic operations to transform keys into array indices. 
  Search algorithms that use hashing consist of two separate parts. The first step is to compute a hash function that transforms the search key into an array index. Ideally, different keys would map to different indices. This ideal is generally beyond our reach, so we have to face the possibility that two or more different keys may hash to the same array index. Thus, the second part of a hashing search is a collision-resolution process that deals with this situation.  
 Hash functions. If we have an array that can hold M key-value pairs, then we need a function that can transform any given key into an index into that array: an integer in the range [0, M-1]. We seek a hash function that is both easy to compute and uniformly distributes the keys. 
  Typical example. Suppose that we have an application where the keys are U.S. social security numbers. A social security number such as 123-45-6789 is a 9-digit number divided into three fields. The first field identifies the geographical area where the number was issued (for example number whose first field are 035 are from Rhode Island and numbers whose first field are 214 are from Maryland) and the other two fields identify the individual. There are a billion different social security numbers, but suppose that our application will need to process just a few hundred keys, so that we could use a hash table of size M = 1000. One possible approach to implementing a hash function is to use three digits from the key. Using three digits from the field on the right is likely to be preferable to using the three digits in the field on the left (since customers may not be equally dispersed over geographic areas), but a better approach is to use all nine digits to make an int value, then consider hash functions for integers, described next. 
  Positive integers. The most commonly used method for hashing integers is called modular hashing: we choose the array size M to be prime, and, for any positive integer key k, compute the remainder when dividing k by M. This function is very easy to compute (k % M, in Java), and is effective in dispersing the keys evenly between 0 and M-1. 
  Floating-point numbers. If the keys are real numbers between 0 and 1, we might just multiply by M and round off to the nearest integer to get an index between 0 and M-1. Although it is intuitive, this approach is defective because it gives more weight to the most significant bits of the keys  the least significant bits play no role. One way to address this situation is to use modular hashing on the binary representation of the key (this is what Java does). 
  Strings. Modular hashing works for long keys such as strings, too: we simply treat them as huge integers. For example, the code below computes a modular hash function for a String s, where R is a small prime integer (Java uses 31). 
int hash = 0 
for (int i = 0  i &lt  s.length()  i++)
    hash = (R * hash + s.charAt(i)) % M 
  Compound keys. If the key type has multiple integer fields, we can typically mix them together in the way just described for String values. For example, suppose that search keys are of type USPhoneNumber.java, which has three integer fields area (3-digit area code), exch (3-digit exchange), and ext (4-digit extension). In this case, we can compute the number 
int hash = (((area * R + exch) % M) * R + ext) % M  
  Java conventions. Java helps us address the basic problem that every type of data needs a hash function by requiring that every data type must implement a method called hashCode() (which returns a 32-bit integer). The implementation of hashCode() for an object must be consistent with equals. That is, if a.equals(b) is true, then a.hashCode() must have the same numerical value as b.hashCode(). If the hashCode() values are the same, the objects may or may not be equal, and we must use equals() to decide which condition holds. 
  Converting a hashCode() to an array index. Since our goal is an array index, not a 32-bit integer, we combine hashCode() with modular hashing in our implementations to produce integers between 0 and M-1 as follows: 
private int hash(Key key) {
   return (key.hashCode() &amp  0x7fffffff) % M 
}
    The code masks off the sign bit (to turn the 32-bit integer into a 31-bit nonnegative integer) and then computing the remainder when dividing by M, as in modular hashing. 
  User-defined hashCode(). Client code expects that hashCode() disperses the keys uniformly among the possible 32-bit result values. That is, for any object x, you can write x.hashCode() and, in principle, expect to get any one of the 2^32 possible 32-bit values with equal likelihood. Java provides hashCode() implementations that aspire to this functionality for many common types (including String, Integer, Double, Date, and URL), but for your own type, you have to try to do it on your own. Program PhoneNumber.java illustrates one way to proceed: make integers from the instance variables and use modular hashing. Program Transaction.java illustrates an even simpler approach: use the hashCode() method for the instance variables to convert each to a 32-bit int value and then do the arithmetic. 
  We have three primary requirements in implementing a good hash function for a given data type: 
   It should be deterministicâ€”equal keys must produce the same hash value. 
   It should be efficient to compute. 
   It should uniformly distribute the keys. 
  To analyze our hashing algorithms and develop hypotheses about their performance, we make the following idealized assumption. 
 Assumption J (uniform hashing assumption). The hash function that we use uniformly distributes keys among the integer values between 0 and M-1. 
 Hashing with separate chaining. A hash function converts keys into array indices. The second component of a hashing algorithm is collision resolution: a strategy for handling the case when two or more keys to be inserted hash to the same index. A straightforward approach to collision resolution is to build, for each of the M array indices, a linked list of the key-value pairs whose keys hash to that index. The basic idea is to choose M to be sufficiently large that the lists are sufficiently short to enable efficient search through a two-step process: hash to find the list that could contain the key, then sequentially search through that list for the key. 
  Program SeparateChainingHashST.java implements a symbol table with a separate-chaining hash table. It maintains an array of SequentialSearchST objects and implements get() and put() by computing a hash function to choose which SequentialSearchST can contain the key and then using get() and put() from SequentialSearchST to complete either job. Program SeparateChainingLiteHashST.java is similar but does it using an explict Node nested class. 
 Proposition K. In a separate-chaining hash table with M lists and N keys, the probability (under Assumption J) that the number of keys in a list is within a small constant factor of N/M is extremely close to 1. of N/M is extremely close to 1. (Assumes an idealistic hash function.) 
  This classical mathematical result is compelling, but it completely depends on Assumption J. Still, in practice, the same behavior occurs. 
 Property L. In a separate-chaining hash table with M lists and N keys, the number of compares (equality tests) for search and insert is proportional to N/M. 
 Hashing with linear probing. Another approach to implementing hashing is to store N key-value pairs in a hash table of size M &gt  N, relying on empty entries in the table to help with with coll
