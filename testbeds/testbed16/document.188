What The Pirate Bay Can Teach Us about the New RAIC Cloud Deployment Model
Nov 15, 2012
It’s really interesting to see that the Pirate Bay just found a new reason to get rid of its physical servers in exchange for moving to the cloud. Sure, lots of companies have made the move from physical servers to virtual servers to cloud, but it’s ironic that the Pirate Bay is inadvertently leading the charge towards more resilient cloud computing. The new Pirate Bay architecture is a highly variable cloud environment that looks more like an ambient cloud, or at least a distributed cloud, than a centralized cloud.



The history of the cloud has taught us that things on the fringe tend to push the evolution of new Internet technologies. Not a lot of people know, for instance, that online video and videoconferencing were pioneered not for boardrooms, but for bedrooms – as in adult entertainment.

Here, the Pirate Bay needs such high-availability because of the constant industry attempts to take the service down. They are an example of extreme evolution in the cloud. Their availability needs were stressed much more than most any enterprise, so they evolved what I believe is an early example of how most enterprises will run their cloud services several years from now.

I am certain that the high-availability benefits of this model, which just got named “redundant array of inexpensive clouds” (RAIC) will lead it to be used for larger enterprise deployments. It shares elements in common with P2P networks, and even content distribution networking, but it’s differentiated in that it is based upon using Infrastructure as a Service based clouds as the hosting model. Sweet. What they’ve done is basically take the old site failover model of active-active, and turn it into a much broader form of active-active-active-active-active, knowing full well that any node may go away at any time.

It’s also meta. Cloud providers use n+1 scaling to provide (sort of) high availability clouds. Using n+1 across multiple cloud providers is even better.

The holy grail for large enterprise IT is to be able to deploy an application that runs in multiple clouds simultaneously so that you can have very high-availability even if one cloud provider goes down. In fact, it is this dynamic that drove the development of multiple competitors in the CDN space. Large companies distributing huge volumes of files – like Trend Micro – did not want to be beholden to, or reliant on, a single CDN cloud provider. That’s why they historically spread their load between at least two different CDN providers. Better availability, along with more leverage to negotiate, makes for a pretty sweet deal. No matter how good your cloud provider is, adding another will always increase availability, assuming your load balancing and failover is flawless.

There’s one major problem with the way the Pirate Bay is handling the availability problem. They have a centralized load balancer which is an obvious point of attack. There is no reason for this that I can see. When I was VP of Technology for a company called Zeus Technologies (now a part of Riverbed), we made a full-featured virtual appliance load balancers that could run in the cloud. That means that, in an ideal world, the Pirate Bay could simply move away from a hardware-based load balancer in order to run several instances of load bouncers at different cloud providers, which would make their security and availability in the cloud even more bulletproof.

The side effect of a deployment model like this is that it enforces rigorous use of policy-based management in the cloud. It is enough work to secure one infrastructure as a service deployment using advanced tools like secure cloud, but managing rapidly moving instances of clouds on multiple providers in real time requires very focused, very rigorous policy. This is a good thing, because it enhances security, rather than weakening it. I welcome the deployment of more fluid, complex cloud infrastructures like this, because it will bring security to the forefront of the conversation, making it as important as availability. This is a good thing, because if you don’t have security, you don’t have availability either when your site gets hacked.

As a matter of fact, it’s not just enterprises that benefit from this.  Darpa’s Information Innovation Office started a “cyber resilience” effort in 2010, aimed at making all computing more secure and more available. Guys, if you’re reading this, look at what the Pirate Bay did. You’ll be designing systems like this in 5 years.

The enemy of progress here, funny enough, will be cloud providers themselves. The Pirate Bay RAIC architecture treats Infrastructure as a Service providers as commodities, simply disposable entities to be discarded at a moments notice. It makes sense that cloud service providers wouldn’t like this because they prefer differentiated, high-margin services, just like all companies with service businesses.

It goes deeper than that, however. Imagine if you were a cloud provider with a bunch of highly ephemeral customers, but you received takedown notices from various governments around the world, whenever a low-margin instance was suspected of being misused. It would be an operational disaster and make clouds very expensive to run. The most likely outcome here is that the RAIC model will at first drive availability and security up, and cloud costs down, but over time, it will impact the cloud computing model fundamentally. Cloud providers that do not implement systemwide policy-based management at a very granular level will find it’s difficult to keep up with increasingly mobile cloud customers, and increasingly frantic requests from government entities seeking to know who is doing what on the cloud.

What do you think? Do you see yourself running your workload spread across multiple clouds in a RAIC style? When?