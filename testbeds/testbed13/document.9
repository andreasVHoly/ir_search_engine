|  |

|  |

|  
---|---|---  
  
|

|  
|

About Us | Newsletter Sign Up

Home

News

Opinion

Messages

Authors

Video

Slideshows

Teardown

Education

EELife

Events

Android

Automotive

Embedded

Industrial Control

Internet of Things

MCU

Medical

Memory

Open Source

PCB

Planet Analog

Power Management

Programmable Logic

Prototyping

SoC

Test & Measurement

Wireless & Networking

|  
|  |  |  |  |  |  
  
|  
|  |

Breaking News

NEWS & ANALYSIS: Microchip, Micrel CEOs Duel Over Deal

BLOG: $40B Power Management Market Ripe for Innovation

BLOG: How Intel Missed the Smartphone Call

NEWS & ANALYSIS: Radio Show Taps into Sensor Nets

NEWS & ANALYSIS: How Google Made Chromecast Cool

Sponsored link: View ADI's Free Powerful Circuit Design Tools Today

|  |  
|  |

|  |  |  |  |  |  |  
---|---|---|---|---|---|---  
|

News & Analysis

# Is D-Wave a Quantum Computer?

Critics charge its not a "real" QC

**R. Colin Johnson**

5/14/2015 08:52 PM EDT  
9 comments

NO RATINGS

  * Login to Rate

Tweet

PORTLAND, Ore.--Recently I had to explain to a reader why critics say that
D-Wave's so-called quantum computer was not a "real" quantum computer, the
answer for which he accepted on my authority. However, the question kept
nagging me in the back on my mind "why" D-Wave markets what it calls a quantum
computer if it is not for real. To get to the bottom of it, I asked Jeremy
Hilton, vice president of processor development of D-Wave Systems, Inc.
(Burnaby, British Columbia, Canada) about why critics keep saying its quantum
computer is not for real. He also revealed details about D-Wave's next
generation quantum computer.

"The Holy Grail of quantum computing to build a 'universal' quantum computer--
one that can solve any computational problem--but at a vastly higher speed
that today's computers," Hilton told EE Times. "That's the reason some people
say we don't have a 'real' quantum computer--because D-Wave's is not a
'universal' computer."

D-Wave's quantum computer, rather, only solves optimization problems, that is
ones that can be expressed in a linear equation with lots of variables each
with its own weight (the number that is multiplied times each variable).
Normally, such linear equations are very difficult to solve for a conventional
'universal' computer, taking lots of iterations to find the optimal set of
values for the variables. However, with D-Wave's application-specific quantum
computer, such problems can be solved in a single cycle.

"We believe that starting with an application-specific quantum processor is
the right way to go--as a stepping stone to the Holy Grail--a universal
quantum computer," Hilton told us. "And that's what D-Wave does--we just to
optimization problems using qubits."

D-Wave's 512 superconducting niobium qubits on a silicon substrate.  
(Source: D-Wave)

D-Wave's current quantum processor has 512 qubits, allowing it to solve
optimization problems with less than or equal to 512 variables in single
machine cycle. To solve qubit-based optimization problems, D-Wave uses a
different model for computation than a universal computer, called the
adiabatic (occurring without loss or gain of heat) instead of the approach
take by everyone working toward a universal quantum computer--the normal
gates-based model when qubits are processed in the quantum computer in a
manner similar to conventional computers.

"The goal of the adiabatic method is to keep the qubits in their lowest energy
state, which is where they are at the beginning and end of a optimization
problem," Hilton told us. "When the weights of the variables are input the
qubits go into an excited state, but quickly relax into their lowest energy
state, thereby revealing the optimal values of the variables."

D-Wave gets about 100 quantum computer chips per wafer (two shown here) which
is mounts on a super-cooled mounting (middle below).  
(Source: D-Wave)

Those working toward a universal quantum computer today are obsessed with
error correction methods--using up to thousands of qubits just to ensure that
the superposition of values in a quantum state (part 0 and part 1) is
maintained accurately throughout all of its calculations. With the adiabatic
method, Hilton claimed, you don't need error correction because the qubits
naturally relax into their lowest energy state.

"Our qubits go from excited level to a relaxed level, they don't need error
correction at this point," Hilton told us. "But with gate-model of a universal
quantum computer you need error correction to get anything to work at all."

**Companies are investing**  
"What struck me when I talked to D-Wave is that they are rather modest," Mike
Battista, senior manager and analyst of Infrastructure at Info-Tech Research
Group. (London, Ontario, Canada) told EE Times. "They are excited about their
technology, but dont over-promise on its potential."

Battista also cited how D-Wave is pioneering more than just quantum computing,
but also accumulating experience with new paradigms--like superconductivity--
that could keep Moore's Law going.

Jeremy Hilton, vice president of processor development of D-Wave, holding the
"Vesuvius" 512-qubit module that will be supercooled down to .2 milliKelvin
using a 10kWatt refrigerator.  
(Source: D-Wave)

"Their superconducting semiconductors have advantages even outside of being
able to perform quantum computing, such as releasing no heat at all," Battista
told us. There is also the potential for the technology to improve
exponentially, perhaps being able to carry the next paradigm that continues
Moores Law when traditional transistors reach their physical limits."

When asked why critics claims its not a "real" quantum computer and they
should not be calling it such, Battista had a reasoned answer as to why its
going the right direction.

"I know testing of the D-Wave hardware has been mixed, but I understand why
large companies are investing in it anyway," Battista told us. "If there is
even a small chance that this is the next foundational technology that
underlies computing for the next few decades, the investments will be worth
it. Companies that get a head start in developing algorithms and finding
problems that are amenable to quantum computing will be at a huge advantage
if/when viable hardware emerges."

**Next Page:** **Redesigned the architecture**

Email This

Print

Comment

Page 1 / 2 Next >

More Related Links

Microchip, Micrel CEOs Duel Over Deal

Chip Sales Edge Up Slightly

Chips for Energy Harvesting: The Next Billion-Dollar Market

Cypress to Pay $550 Million for Broadcoms IoT Business

Marvell Shakes up Board in Deal with Hedge Fund

Comments

View Comments:  **Newest First** | Oldest First | Threaded View

[close this box]

User Rank  
Rookie

512 qubits...really?  
John K Sellers   6/8/2015 4:32:08 PM

NO RATINGS

  * Login to Rate

If an entanglement has 512 qubits, then it has about 1.34 times 10 raised to
the 154 power superimposed states.  
  
The real trouble is that quanitative scaling like that implies a qualitative
change as well.  
  
let us make clear what I mean by example.  If you have one horse, a saddle
will work just fine.  But if you have 4 horses, 4 saddles aren't going to help
you pull a wagon.  You need something else altogether.  
  
So what are you going to do to handle our 512 entangled qubits?  This may be
too complicated to ever be able to manage.  The properties of an entaglement
are holistic and do not reside in each qubit, but exist only as a whole.  You
can't just look at a qubit and check off the state of each of its bits else it
would be pretty straight forward to read out an answer.  What you will
probably (pun intended) have to do since our only tool is statistics is gather
enough samples to precisely charactgerize what is going on.  And those samples
will not be in the conext of a qubit or a particular state, but will be in the
context of so many states that it is impossible to count them all much less
comprehensively examine them.  
  
So let me ask you a question, how many statistical samples would you have to
have to characterize over 10 raised to the 154 power superimposed states?  And
how easy would this be to do even assuming we could somehow gather such
samples when our entanglement colapses every time we look at it?  
  
Personally I don't think we will ever be able to do it.  
  
  
  
  
  

Reply   Post Message   Messages List   Start a Board

User Rank  
Author

Re: quantum analog computers  
R_Colin_Johnson   5/18/2015 4:55:44 PM

NO RATINGS

  * Login to Rate

traneus: You may be more right than your most optimistic prediction. Most
researchers are going after a "universal" quantum computer that could replace
conventional computers, but D-Wave's application-specific version may already
be the end-game. If companies built more-and-more application-specific quantum
computers like D-Wave's, but aimed at different difficult problems today (such
as linear speedups of massively parallel computers) the quantum computer may
end up being like the GPU--an add-on accelerator speeding up the problems at
which the multi-core solution performs poorly.  
  

Reply   Post Message   Messages List   Start a Board

User Rank  
Author

quantum analog computers  
traneus   5/18/2015 4:37:46 PM

NO RATINGS

  * Login to Rate

Quantum computers are analog computers: They use physical analogs of the
desired functions to find their results. As such, quantum computers are
limited by noise, outside interference and other manifestations of physical
reality. This makes building large quantum computers very difficult.  
  
Fifty and more years ago, classical analog computers were discussed more than
they are now. We still build analog computers, though we seldom use the term:
Every time we use an opamp, we are building an analog computer: The term
"operational amplifier" came from the analog-computer world.  
  
Large, fast quantum computers would be useful for certain classes of problems:
Those where finding solutions requires exhaustive search of large data spaces,
but where checking potential solutions for correctness is fast and easy. One
example is Shor's algorithm for rapidly factoring large integers using a large
quantum computer.  
  
Present-day quantum computers are useful to graduate students as topics for
master's and doctoral theses.  
  

Reply   Post Message   Messages List   Start a Board

User Rank  
Author

Re: a couple of basic questions  
R_Colin_Johnson   5/15/2015 3:27:59 PM

NO RATINGS

  * Login to Rate

The qubits precision cannot be specified in coventional terms, and you are
right about the typo using variable twice, I'll fix that now :)  
  

Reply   Post Message   Messages List   Start a Board

User Rank  
Author

a couple of basic questions  
DCH0   5/15/2015 3:03:28 PM

NO RATINGS

  * Login to Rate

Forgive a couple of basic questions, but I suspect I am not the only one who
is a bit overwhelmed by qubits.  
  
"D-Wave's current quantum processor has 512 qubits, allowing it to solve
optimization problems with less than or equal to 512 variables in single
machine cycle."  How many bits are in a variable?  Does it use a number of
processors equal to the number of bits?  
  
From Colin's response on neural networks "Most neural network models use
linear equations, where the variables are the constants are the synaptic
values and the variables are the inputs from the problem being solved."  Was
this a typo with variables being used twice?  
  

Reply   Post Message   Messages List   Start a Board

User Rank  
Author

Re: machine cycle  
R_Colin_Johnson   5/15/2015 12:07:32 PM

NO RATINGS

  * Login to Rate

Your are right. Most neural network models use linear equations, where the
constants are the synaptic values and the variables are the inputs from the
problem being solved. Its hard to understand why D-Wave did not concentrate on
that application from the beginning, but they claim to be hot-on-the-trail of
neural network solutions now that they have been popularized as "deep
learning".  
  

Reply   Post Message   Messages List   Start a Board

User Rank  
Author

Re: machine cycle  
dt_hayden   5/15/2015 11:39:59 AM

NO RATINGS

  * Login to Rate

Colin,  I found the following info in a paper* on D:Wave site:  the computer
returns ... 10,000 answers in one second.  
  
Aftr reading the paper, it strikes me A LOT as the same principle as "neural
networks" but implmented in a parallel computing fashion rahter than
sequential.   The issue I have with my understanding or neural networks is
that the system only works if "trained" on all possible data sets.  Perhaps
the fact that quantum computing can perform each analysis in parallel rather
than sequential, this is no big deal.  
  
This is an interesting topic I am looking forward to understanding better.  
  
  
  
* http://www.dwavesys.com/sites/default/files/Map%20Coloring%20WP2.pdf  
  

Reply   Post Message   Messages List   Start a Board

User Rank  
Author

Re: machine cycle  
R_Colin_Johnson   5/15/2015 10:58:53 AM

NO RATINGS

  * Login to Rate

dt_hayden: Thanks for your comment. A machine cycle for a D-Wave computer
begins by loading its qubits with the weights (mutipliers) of the variables in
the linear equation, which perturbs it from its ground-state (lowest energy
state), then waiting for it to settle into a new ground state, then read-out
the values of the variables.  
  

Reply   Post Message   Messages List   Start a Board

User Rank  
Author

machine cycle  
dt_hayden   5/15/2015 10:31:59 AM

NO RATINGS

  * Login to Rate

"allowing it to solve optimization problems with less than or equal to 512
variables in single machine cycle."  
  
So what constitutes a machine cycle?  
  
  
  
This is certainly a paradigm shift in thinking.  All I can equate it to in my
mind is an analog computing process along the lines of "artificial
intelligence" or "expert systems" which were fads of the past.  Not to say
this is a fad.  
  

Reply   Post Message   Messages List   Start a Board

|  |  |  |

Most Recent Comments

















5/4/2016  
6:43:09 PM

**antedeluvian** Their ads were very fun and creative; Pity their customer service stank. I still get nightmares about how they literally reduced me to tears.

5/4/2016  
6:43:09 PM

**antedeluvian** Their ads were very fun and creative; Pity their customer service stank. I still get nightmares about how they literally reduced me to tears.

5/4/2016  
6:31:46 PM

**Stargzer** Bob found out to his distress that when he dropped his waterproof Bluetooth headset into the front lobby's tropical fish tank last Friday, the RF caused the...

5/4/2016  
6:29:25 PM

**Eric Verhulst_Altreonic** The issue is a fake one. Smartphones/tablets are now a commodity, just like PCs became that a while ago. The new upcoming market is mobility. There is a lot of processing needed...

5/4/2016  
5:36:34 PM

**traneus** Max, you might put a radio in your diorama, for listening to the original BBC radio version of Hitchhiker's Guide to the Galaxy.

5/4/2016  
4:44:45 PM

**TonyTib** Yep; IIRC they were based in cow country (North Dakota?), and thus prominently featured cows.  They fell on hard times quite a while ago, got bought, and I think even the...

5/4/2016  
4:26:35 PM

**David Ashton** @Tony Tib - Are you talking about the ones with B&amp;W; cowhide  markings on the boxes?  The mags used to be full of them but even google couldn't come up with much now...

5/4/2016  
3:07:29 PM

**realjjj** Icahn at Apple just went after the cash as Apple had a lot of it and he got it. He doesn't really know Apple though and stayed too long, he should have gotten out when the Watch...

5/4/2016  
3:04:51 PM

**elizabethsimon** You want your money to work hard - so do I. But do you want to maximize short term profits at the expense of long term growth? Unfortunately, the way the market operates, many...

5/4/2016  
2:57:56 PM

**BrainiacV** Bob realized he must have miss spelled terabyte as tearabytes on the order form.

Navigate to Related Links

Microchip, Micrel CEOs Duel Over Deal

Chip Sales Edge Up Slightly

Chips for Energy Harvesting: The Next Billion-Dollar Market

Cypress to Pay $550 Million for Broadcoms IoT Business

Marvell Shakes up Board in Deal with Hedge Fund

#### Datasheets.com Parts Search

##### 185 million searchable parts  
(please enter a part number or hit search to begin)

Cartoon

Contest

May 2016 Cartoon Caption Contest "That Bites!"

"Your caption here!"

34 comments

All Cartoons

April 2016 Cartoon Caption Contest "April Fool"

"Your caption here!"

95 comments

All Cartoons

Most Commented

Most Popular

 95    Max Faces Cease-and-Desist Order

 57    Time Portal Tribute to Classic Science ...

 45    Brussels and Whats Really Important

 39    Happy Square Root Day!

 36    Standing at the Crossroads of Coherence & ...

 36    Google, Can You Teach Me to Play Go?

 32    MCU Guy, Meet FPGA; FPGA, Meet MCU Guy

 31    Fixing C

 29    To Sleep, Perchance to Dream, Perchance ...

 28    Uber-Cool iClever Folding Bluetooth Keyboard

 15    Intel to Exit Mobile SoC Business

 11    Novel Soldering Technique Using Pseudo TIG ...

 10    Activist Investor Attacks Vex Chipmakers

 9    How Intel Missed the Smartphone Call

 8    T.J. Rodgers Steps Down at Cypress

 7    Smartphone Shipments Down for First Time

 7    Trade Secret Bill Boosts Protection

 6    Microchip, Micrel CEOs Duel Over Deal

 4    Solar Plane Takes Off on Next Leg

 3    Coding Challenge: Can You Improve My BMP ...

Like Us on Facebook

EE Times on Twitter

follow us

Tweets about "from:eetimes"

|  
|

_Sign up for EE Times newsletter_

|  
  
  * **GLOBAL NETWORK**
  * EE Times Asia
  * EE Times China
  * EE Times Europe
  * EE Times India
  * EE Times Japan
  * EE Times Korea
  * EE Times Taiwan
  * EDN Asia
  * EDN China
  * EDN Japan
  * ESC Brazil

  * **UBM Communities**

  * EE Times
|

  * EDN
|

  * EBN
|

  * DataSheets.com
|

  * Embedded
|

  * TechOnline
|

  * Design News
|

  * DesignCon
|

  * ESC

  * **Working With Us:**
  * About
|

  * Editorial Policies
|

  * Contact Us
|

  * Media Kits
|

  * Reprints

  * Terms of Service
|

  * Privacy Statement
|

  * Copyright (C) 2016 UBM All Rights Reserved

  
  
|  
  
  * To rate this item, click on a rating below.

  *   *   *   *   *   * [close this box]

  *  

  * To save this item to your list of favorite EE Times content so you can find it later in your Profile page, click the "Save It" button next to the item.

  *  

  * If you found this interesting or useful, please use the links to the services below to share it with other readers. You will need a free account with each service to share an item via that service.

  * Tweet This
  * [close this box]

Latest News

Semiconductor News

Blogs

Message Boards

Advanced Technology

Analog

Boards/Buses

Electromechanical

Embedded Tools

FPGAs/PLDs

IP/EDA

Logic & Interfaces

Memory

Operating Systems

Optoelectronics

Passives

Power

Processors

RF/Microwave

Sensors & Transducers

Test & Measurement

ARM Techcon

DesignCon

Designers of Things

ESC

EETimes University

Tech Papers

Courses

   Fundamentals

Webinars

Design West

DesignCon

ARM Techcon

