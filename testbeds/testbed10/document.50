Financial credit is an immense global industry. In the United States alone the annual transactions of Visa, Mastercard, Discover, and American Express credit cards totaled $1.2 trillion from over 500 million cards in circulation. The outstanding level of consumer debt in the U.S. totals about $1.5 trillion, with high interest credit card loans comprising $568.4 billion of that total. More than 4% of credit cardloans are delinquent andplacedfor collection every year. U.S. bankruptcy &lings for the year 2002–2003 set a recordlevel, totaling 1,650,279, which includes 37,182 business bankruptcy &lings. There is a clear need for accurate decision support for both the credit granting decision and the monitoring of the ongoing health of credit customers. An improvement in accuracy of even a fraction of a percent translates into signi&cant future savings for the credit industry. Traditional methods of &nancial decision support include scorecards for consumer credit [1–5] and discriminant models for assessing corporate &nancial health [6,4]. Both are essentially multivariate linear models that output a probability that the client will repay debt as agreed. Recent research interest has focusedon more complex nonlinear models, particularly neural networks, to increase the credit decision accuracy [2,6–19]. The reader is referredto Smith andGupta [20] for a recent survey of the application of neural networks in a diverse range of operations research problems that include &nancial forecasting and creditworthiness. The focus of prior research has been to identify the “single best” model that is most accurate for a given &nancial decision application. This reliance on a single model may be misguided. Recent studies of ensembles (or committees) of predictors have demonstrated the potential to reduce the generalization error of a single model from 5% to 70% [21,22]. Three major strategies have been advanced for forming ensembles of predictors. The simplest is the crossvalidation (CV) neural network ensemble where all ensemble members are trainedwith the same data [23,16]. The second andthirdstrategies create perturbedversions of the training set so that ensemble members learn from di1erent variants of the original training data. Bagging ensembles create a unique training set for each ensemble member by sampling with replacement over a uniform probability distribution on the original data [21,24,25]. This creates training sets where some observations are replicated andothers may be missing. Boosting is also a re-sampling strategy, with a probability distribution that is dependent on the misclassi&cation rate for each observation [26,16]. Boosting is an iterative algorithm where the probability of the misclassi&edobservations is increasedandthe corresponding probability of correctly classi&edobservations is decreasedover time. As boosting progresses, the composition of the training sets becomes increasingly dominated by hard-to-classify examples. The purpose of this research is to investigate the accuracy of ensembles of neural networks formedfrom these three strategies for credit granting and bankruptcy decision applications. In the next section of this paper we review the recent theory andapplication of ensembles, with particular attention given to neural networks. Speci&c research questions are de≠d in this section. The research methodology is described in Section 3, andin Section 4 the comparison of generalization errors for the neural network ensemble strategies is discussed. We conclude in Section 5 with guidelines for implementing neural network ensembles for &nancial decision applications. 

Recent research has focused on the identi&cation of higher capacity nonlinear models to improve the generalization accuracy of &nancial decision applications. A better approach than the reliance on a single high capacity model is to pursue ensemble strategies that combine the predictions of a collection of individual models. The results of this research con&rm that ensembles of neural network predictors are more accurate and more robust that the “single best” MLP model based on experiments with three real world&nancial data sets. The ensemble strategies employedin this research reduced the generalization errors estimated for the single model case by 3.26% for the Australian credit, 4.44% for the German credit, and 3.88% for the bankruptcy data. All three di1erences are statistically signi&cant reductions in generalization error. While an error reduction of 3–5% may seem modest, the reader must appreciate that the global credit industry has transactions exceeding $1 trillion annually. Based on an annual write o1 rate of 4%, a decision technology that is capable of reducing classi&cation errors by 3% couldpotentially save the industry $1.2 billion annually. It is more diQcult to make a design recommendation for ensemble strategies that introduce diversity by intentionally perturbing the training set using bootstrap or boosting algorithms. Our aggregate analysis &nds no signi&cant di1erence in accuracy between the perturbation strategies and the simple CV ensemble. However, we do note that each of the three ensemble strategies investigated achieved a statistically signi&cant reduction in error in at least one application. The CV ensemble was most accurate for the German credit data, an application characterized by high noise levels, a relatively large training set size, anda large number of feature variables. The bagging strategy was most e1ective for the Australian credit and the bankruptcy data set, both characterized by smaller training samples, fewer feature variables, andless noise. The boosting strategy was e1ective only for the bankruptcy data, the smallest data set with the fewest number of feature variables and the least amount of noise. While 25–30 ensemble members are adequate for the CV and bagging ensembles, we note as many as 100 members are necessary for the boosting ensemble.
