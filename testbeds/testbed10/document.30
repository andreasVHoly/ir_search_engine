As the amount of information on the World Wide Web grows, it becomes increasingly difficult to find just what we want. While general-purpose search engines such as AltaVista and Google offer quite useful coverage, it is often difficult to get high precision, even for detailed queries. When we know that we want information of a certain type, or on a certain topic, a domain-specific Internet portal can be a powerful tool. A portal is an information gateway that often includes a search engine plus additional organization and content. Portals are often, though not always, concentrated on a particular topic. They usually offer powerful methods for finding domain-specific information. For example:– Camp Search (www.campsearch.com) allows the user to search for summer camps for children and adults. The user can query and browse the system based on geographic location, cost, duration and other requirements. – LinuxStart (www.linuxstart.com) provides a clearinghouse for Linux resources. It has a hierarchy of topics and a search engine over Linux pages. – Movie Review Query Engine (www.mrqe.com) allows the user to search for reviews of movies. Type a movie title, and it provides links to relevant reviews from newspapers, magazines, and individuals from all over the world. – Crafts Search (www.bella-decor.com) lets the user search web pages about crafts. It also provides search capabilities over classified ads and auctions of crafts, as well as a browseable topic hierarchy. – Travel-Finder (www.travel-finder.com) allows the user to search web pages about travel, with special facilities for searching by activity, category and location. Performing any of these searches with a traditional, general-purpose search engine would be extremely tedious or impossible. For this reason, portals are becoming increasingly popular. Unfortunately, however, building these portals is often a labor-intensive process, typically requiring significant and ongoing human effort. This article describes the use of machine learning techniques to automate several aspects of creating and maintaining portals. These techniques allow portals to be created quickly with minimal effort and are suited for re-use across many domains. We present new machine learning methods for spidering in an efficient topic-directed manner, extracting topic-relevant information, and building a browseable topic hierarchy. These approaches are briefly described in the following three paragraphs. Every search engine or portal must begin with a collection of documents to index. A spider (or crawler) is an agent that traverses the Web, looking for documents to add to the collection. When aiming to populate a domain-specific collection, the spider need not explore the Web indiscriminantly, but should explore in a directed fashion in order to find domain-relevant documents efficiently. We set up the spidering task in a reinforcement learning framework (Kaelbling et al. 1996), which allows us to precisely and mathematically define optimal behavior. This approach provides guidance for designing an intelligent spider that aims to select hyperlinks optimally. It also indicates how the agent should learn from delayed reward. Our experimental results show that a reinforcement learning spider is twice as efficient in finding domain-relevant documents as a baseline topic-focused spider and three times more efficient than a spider with a breadth-first search strategy. Extracting characteristic pieces of information from the documents of a domain-specific collection allows the user to search over these features in a way that general search engines cannot. Information extraction, the process of automatically finding certain categories of textual substrings in a document, is well suited to this task. We approach information extraction with a technique from statistical language modeling and speech recognition, namely hidden Markov models (Rabiner 1989). We learn model structure and parameters from a combination of labeled and distantly-labeled data. Our model extracts fifteen different fields from spidered documents with 93% accuracy Search engines often provide a hierarchical organization of materials into relevant topics; Yahoo is the prototypical example. Automatically adding documents into a topic hierarchy can be framed as a text classification task. We present extensions to a probabilistic text classifier known as naive Bayes (Lewis 1998, McCallum and Nigam 1998). The extensions reduce the need for human effort in training the classifier by using just a few keywords per class, a class hierarchy and unlabeled documents in a bootstrapping process. Use of the resulting classifier places documents into a 70-leaf topic hierarchy with 66% accuracy— performance approaching human agreement levels. The remainder of the paper is organized as follows. We describe the design of an Internet portal built using these techniques in the next section. The following three sections describe the machine learning research introduced above and present their experimental results. We then discuss related work and present conclusions.
