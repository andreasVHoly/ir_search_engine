
A fundamental problem of machine learning is dealing with large spaces of possible hypotheses. Usually, this problem is addressed either by biasing learning towards simpler hypotheses, i.e. applying Occam’s razor, or by using experts’ domain knowledge for constraining search. Domingos [9] argues that the Occam’s razor approach is valid only if we honestly believe that the target phenomenon is simple, and therefore prefers the use of domain knowledge. Existing machine learning paradigms typically enable, at least in some limited form, the use of general domain knowledge, that is knowledge that holds for the whole domain. The problem with this is the difficulty that experts face when they try to articulate their global domain knowledge. In this paper, we present a novel approach for constraining search, that allows the use of “local” expert’s knowledge. That is knowledge relating to specific situations, perhaps only valid for chosen learning examples rather than for the whole domain. In this approach, the domain expert explains some of the learning examples, and these examples are then, together with other examples, used in the learning algorithm. Explanation of examples is in terms of arguments for and against, therefore we call such examples argumented examples. The learning from such examples is called argument based machine learning (ABML), introduced by Bratko and Možina in [2]. ABML combines machine learning with some ideas from the field of argumentation [21]. Defeasible argumentation is a branch of artificial intelligence that analyzes processes of reasoning where arguments for and against a certain claim are produced and evaluated. A typical example of such reasoning is a law dispute at court, where plaintiff and defendant give arguments for their opposing claims, and at the end of the process the party with better arguments wins the case. In this paper we propose a realization of ABML as an algorithm that learns if-then rules from argumented examples. In Section 2 we describe the motivation and basic ideas for argument based machine learning. In Section 3 we develop an actual implementation of argument based machine learning, i.e. argument based CN2 (ABCN2 for short) as an extension of the well-known rule learning algorithm of Clark and Niblett [7]. In Section 4, we demonstrate and analyze the advantages of ABCN2 over the original CN2 on several data sets and conduct, in Section 5, an experiment that shows the effect of unreliable, or noisy arguments on the quality of induced model. This paper is a substantial extension of our earlier conference paper on the idea of AB enhancement of CN2 [16]. The extensions include the experiments with ABCN2 (except for the illustration with the zoo domain), extreme value correction of probability estimate in ABCN2 (an essential improvement applicable also in CN2), and an experimental study of the effect of errors in arguments on the success of learning. It should be noted that argument based ML is not limited to CN2, nor to rule learning. Various standard ML techniques can be extended in a similar way to their argument-based variants, for example argument-based Naive Bayes, or support vector machines (SVM), or inductive logic programming (abbreviated AB-ILP). However, rule learning is the most natural framework for developing ABML techniques. In rule learning, both induced theories and arguments are represented in the same language, which is desirable. Also, rule learning has the desirable property of comprehensibility of induced theories, and the influence of user’s arguments is explicitly visible in induced rules. In contrast to this, applying the ABML approach for example to SVM would not exhibit these two desirable properties. On the other hand, we would expect that the use of arguments would result in improvement in classification accuracy also in SVM, as well as in other ML methods. 
In this paper we have described a novel approach to machine learning that draws on some concepts of argumentation theory. We introduced a new type of examples, argumented examples. Arguments are used to constrain the search among possible hypotheses. We implemented ABCN2, an argument based extension of CN2. We have shown several advantages of argument based approach to learning rules:
• Expressing expert knowledge in the form of arguments for individual examples is easier for the expert than providing general theories. • Critical examples whose arguments are expected to most improve the learning, are automatically identified by our method. • ABCN2 produces more comprehensible rules than CN2, because it uses expert-given arguments to constrain learning, thereby suppressing spurious hypotheses. • In the experiments with a number of test data sets (ZOO, Credit data, South African heart disease domain, legal domain, and infections domain), ABCN2 achieved higher classification accuracy than classical CN2. Although this might not be true for all domains, we can expect that arguments will, in general, improve accuracy of hypotheses. We showed experimentally that, on average, imperfect, or even completely random arguments are unlikely to harm the classification accuracy of ABCN2. The number of experimental domains in our experiments with ABCN2 is relatively low in comparison with typical experimental work in machine learning, so further experiments with the method will be useful. It should be noted however that experimenting with argument-based learning methods is more demanding than the usual experimentation in machine learning using e.g. UCI data sets. ABML requires the involvement of an expert, or at least some other source of knowledge, to provide arguments and assess the results of learning from the semantic point of view. The extreme value correction in probability estimates is a substantial improvement for rule learning. However, it comes at computational cost. The initial determination of the parameters of the extreme value distribution for the particular learning problem is typically roughly comparable to the rest of rule learning in ABCN2. One aspect that deserves investigation is related to the appropriateness of expert-supplied arguments. One problem that has been noticed occurs in cases when the expert is overly diligent and provides very specific arguments. These may occasionally prevent ABCN2 from inducing good simpler theories. Another point that may be improved concerns our method of selecting critical examples that are suggested to the expert for explanation. The method selects the most frequently misclassified example. Although this has worked well in the experiments, we feel that the method is debatable and may possibly be improved. The present selection method does not take into account how natural the selected example will be to be explained by the expert in terms of arguments. The selected example may be an outlier which will be troublesome to explain, and resulting arguments may not be useful for learning.
