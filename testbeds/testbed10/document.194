Monotonicity Maintenance in Information-Theoretic
Machine Learning Algorithms


ARIE BEN-DAVID 

1 Introduction
Suppose a college admissions committee decides to use decision trees to determine whom
to admit based on standardized test scores and grades. For reasons such as fairness and
liability, the college would not want to use a decision tree that admits an applicant with
certain scores, and then rejects another who scores as high or higher on each measure.
Similarly, a life insurance company would not wish to rely on a decision tree that quotes a
young and healthy applicant a higher premium rate than one that has been quoted to an old
and unhealthy person.
The classifications in both the school admissions and the life insurance premium problems
are required to be monotonic with respect to the attribute values. These problems are,
therefore, called monotonic classification (MOC) problems. MOC problems are important
because they are very common, and deal with many aspects of our life. In addition to the
examples given above, MOC problems include, among others, credit scoring (Carter, 1987),
consumer choice (Jacoby, 1974), school and transportation selection, investment decisions,
referee and editorial decisions (Larichev, 1988), employee selection, lecturer evaluation,
and certain social workers decisions (Ben-David, 1992), The examples that are used to
construct decision trees for real-world MOC problems are frequently non-monotonic with
respect to each other, in particular, when the examples are taken from past human decisions
(Jacoby, 1974; Hayes-Roth, 1983).
Ideally, decision trees, for MOC problems should be monotonic, regardless of whether
their training sets are monotonic or not. Unfortunately, information-theoretic top-downinduction
decision tree (TDIDT) algorithms (Quinlan, 1986), that use entropy as the criterion for attribute selection may produce non-monotonic decision trees. Figure 1 illustrates two
such cases of simplified credit scoring decision trees. The attributes are assets, and income
+ assets respectively. The decisions are shown at the leaves. It is quite evident that the
decision tree of assets does not make much sense. A client with low assets is authorized a
$ 5K line of credit, while one with more assets is refused. It is easy to show that the income
+ assets decision tree suffers from similar anomalies.
TDIDT algorithms that use the E-score as their attribute selection metric do not consider
the order within the attribute values and among the classes. The same observation applies
to Mantaras's distance-between-partitions measure (Mantaras, 1991), and to Nunez's background
knowledge (Nunez, 1991). Consequently, TDIDT algorithms are not well adapted
to deal with MOC problems. The above shortcoming is shared by some other well known
learning from examples paradigms: Feed-forward neural networks (Rumelhart, 1986),
most of Michalski's AQ family of models (Michalski, 1983), CN2 (Clark & Niblett, 1989),
and Fisher's COBWEB (1987), suffer from the same limitation while dealing with MOC
problems.
However, decision trees are also required to provide acceptable inductive accuracy. Unfortunately,
in real-world cases, these two goals often conflict. Clearly, the tradeoff between
monotonic classifications and inductive accuracy is domain dependent. Legal requirements,
if applicable, push toward monotonicity of classifications (see above). Human-related considerations
also motivate the use of monotonic decision trees, since end-users often consider
non-monotonic classifications of MOC problems as unacceptable (see also Larichev &
Moshkovich, 1988; Ben-David, 1992).
This paper presents a metric that can improve the monotonicity of decision trees, with
little, or no loss of accuracy. The metric's properties are empirically studied on five realworld
MOC problems. 


5 Conclusions and further research
It has been argued that monotonicity of classifications is a very important consideration
while solving MOC problems. Unfortunately, current TDIDT attribute selection measures
do not take monotonicity into account. They may result in non-monotonic decision trees,
even when all the examples in the training set are monotonic with respect to each other. Unlike the E-score, the total-ambiguity-score metric that has been proposed here considers
both monotonicity as well as inductive accuracy.
Using five real-world problem domains, it has been shown that the total-ambiguity-score
generates decision trees with significantly lower non-monotonicity indices than those that
are generated by the E-score metric. More importantly, the former achieves this goal
without a significant deterioration of the inductive accuracy (again, when compared with
ID3's E-score).
Although the discussion has been focused on extensions to Quinlan's well known E-score
attribute selection measure, it is also pertinent to other attribute selection metrics, such
as Quinlan's gain-ratio, or Mantaras's distance-based attribute selection metric. TDIDT
algorithms that were not studied here, such as C4.5 (Quinlan, 1987), ID4 (Schlimmer &
Fisher, 1986), and ID5R (Utgoff, 1989), may also be adapted to deal with MOC problems
using a similar approach.
Since MOC problems are so common in human daily life, it is worthwhile to address some
interesting open questions in future research: For example, the order-ambiguity score, as
defined here, does not take into account the severity of non-monotonic conflicts. A measure
that considers the severity of these conflicts may be helpful for some applications. The
effects of windowing on the performance of the proposed metric are also of interest. Also,
it is worthwhile to investigate whether the inclusion of the order within the attributes and
classes in background knowledge can provide better results than those that were obtained
via the total-ambiguity-score metric.
