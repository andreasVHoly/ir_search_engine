Predicting dire outcomes of patients with community acquired pneumonia

This paper describes a retrospective evaluation of machine-learning and statistical methods that predict the chance of dire outcomes in patients who present with community acquired pneumonia (CAP). We use the term dire outcome to denote a severe complication, death within 30 days of presentation, or an admission to the intensive care unit (ICU) for either respiratory failure, respiratory or cardiac arrest, or shock/hypotension.1 CAP is an important clinical condition, both from the point of view of resource-utilization and patient outcomes. Previous studies have estimated that each year in the US there are about 4.1 million CAP patients of whom approximately 1.2 million are hospitalized [1,2]. Taken together, pneumonia and influenza have been ranked as the sixth leading cause of death in this country [3]. In the US, CAP has been responsible for 64 million days of restricted activity, 39 million days of bed con- finement, and 10 million days of work lost annually [4]. The aggregate cost of hospitalization of CAP patients is estimated to total almost $9 billion per year in the US [5]. One use of predicting the probability of dire outcomes of CAP patients would be to assist clinicians in making the admission decisions for those patients. The admission decision is one of the most cost-sensitive decisions made in the care of CAP patients, with the average cost of care for inpatients being 18–28 times greater than the cost of care for outpatients [5]. Ideally, patients who could be safely treated as outpatients (typically at home) on oral antibiotics would be so treated, while usually the remaining patients would be admitted to the hospital and treated with intravenous antibiotics. Researchers have previously developed models that predict mortality as an outcome of patients with CAP. The PSI model in particular was developed to predict patient mortality within 30 days of presentation with CAP [7], based on 20 demographic and clinical variables. The models described in the current paper predict dire outcomes more broadly than mortality, to include severe complications and admission to the ICU. It seems likely that decisions about where to treat CAP patients are based not just on mortality, but also on other possible dire outcomes. Thus, predicting dire outcomes more broadly seems useful. To learn computer models that predict dire outcomes of CAP patients, we applied several induction methods to a training set (i.e., derivation set) of CAP patient records. These models were then evaluated using a CAP test set (i.e., validation set). The modeling methods we used are logistic regression, rule-based learning, neuralnetworks, finite mixture model techniques, simple (i.e., naı¨ve) Bayes methods, and a combination of finite mixture modeling and simple Bayes. All of these methods have been previously described in the literature, although some of them are likely to be unfamiliar to many readers. Our primary goal was not to compare these learning algorithms as a study end point; rather, it was to develop the best possible model to predict dire outcomes and then estimate the impact of its use on healthcare quality and cost. We describe the predictive performance of each model on the test set, where the area under the ROC curve is used as a measure of performance. These results suggest which of the tested models are likely to perform best in predicting dire outcomes in future patients with CAP. We also describe performance when the training set contains more and more cases. These results indicate whether we can expect further improvement in the models performance if the training set were expanded by collecting additional cases of patients with CAP. Finally, for the model M with the best predictive performance on the full training set, we estimate the impact that M would have on healthcare quality and cost, if it were applied in helping guide decisions about whether to treat CAP patients at home or in the hospital.

Conclusions

On a training and test dataset of CAP patients, we found that there were statistically significant differences in how well different induced models predicted dire outcomes. After approximately 400 training cases, there was little improvement in the ROC area for most of the models induced by most of the methods. Thus, the results appear stable in the large training sample limit. It will be useful to validate these results by testing whether randomly re-sampling subsets of the 1601 training cases leads to similar asymptotic patterns of predictive performance. An innovative neural network learning method induced a model (NN.MTLR) that had the largest ROC area when using all the training cases; statistically, its performance was significantly different from five models constructed using other methods, and not significantly different from five other models. Additional research will be required to determine whether other machinelearning methods that were not tested in our investigation might perform even better than this neural network model.
