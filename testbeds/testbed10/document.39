Content-based image retrieval computes relevance based on the visual similarity of low-level image features such as colors, textures and shapes [1]. However, people prefer retrieving images according to high-level semantic content. The problem is that visual similarity is not semantic similarity. There is a gap between low-level image visual features and semantic meanings. Image annotation techniques are used to bridge the gap [1–3]. As it is laborious, error prone, and subjective, to manually annotate a large collection of images, we hope to do the task automatically. Automatic image annotation is a process of automatically labeling images with a set of pre-defined keywords, which represent image high-level semantic content. Specifically, given a set of images where each image is captioned with keywords that describe image semantic content, we identify correlation between keywords and low-level image visual features. This association combining with a similarity measure is used to automatically annotate unlabeled images [4,5]. Multimedia content description interface (MPEG-7) is one of the most famous multimedia metadata standards, which includes a number of image feature descriptors to represent low-level image features effectively [6,7]. But, the contribution of each descriptor may not be the same for a domain specific image database when computing the similarity measure. The weight of each feature ought to be different according to its importance. Another disadvantage using MPEG-7 is that exhaustively searching the MPEG-7 feature descriptor space can impose a high computational cost. Furthermore, there are redundant feature descriptors in MPEG-7, which decrease the effectiveness of feature representation. In order to improve the performance of image annotation, we exclusively focus on machine learning techniques for feature selection which includes weight optimization which automatically adjusts the weight of each feature descriptor, optimal feature descriptor subset selection and the simultaneity of weight optimization and optimal feature descriptor subset selection. For weight optimization, Wang et al. determined relevant features based on histogram analysis and assigned greater weight to relevant features as compared to less relevant features [8]. Setia et al. formatted image annotation with keywords as a classification problem and used a Gaussian mixture model to weight the features effectively [9]. In [10], Qi et al. applied likelihood normalization to optimize weights for Corel images automatically. They computed the MPEG-7 scalable color descriptor and the modified MPEG-7 edge histogram descriptor to represent the overall color and texture of the image. In the above discussed methods, machine learning algorithms for weight optimization are ignored and few features are considered. In general, feature subset selection approaches can be grouped into two categories: filter method and wrapper method [11,12].Independent of any machine learning algorithm, the filter model selects feature subsets to estimate the performance by some indirect assessments, such as distance measures. The wrapper model, on the contrary, uses the accuracy of a predetermined machine learning algorithm to determine the ‘goodness’ of the selected subsets, which will intuitively yield better performance. The method is computationally expensive for data with a large number of features. Search strategy is a key problem in feature subset selection. To balance the tradeoff of result optimality and computational effi- ciency, a lot of search strategies such as complete, heuristic, and random search have been studied to generate candidate feature subsets for evaluation. Genetic algorithm (GA) is an effective random search approach of wrapper model [13]. In [14], feature selection based on GA whose fitness function combined the number of features to be used and the error rate of the Bayesian classifier was presented. Huang et al. presented a feature optimization approach based on GA and support vector machine (SVM) classification accuracy [13]. Hernández et al. proposed using GA to select a set of suitable regions for the feature extraction in facial expression recognition system [15]. In these methods, MPEG-7 image feature descriptors are ignored. In [16], Hamdani et al. proposed a bi-coded chromosome genetic algorithm to simultaneously select feature subset and the importance rate of each feature. They combined the k-NN recognition rate and the size of the selected feature subset as fitness function. But, it is not used for image annotation. We represent low-level image features with all the MPEG-7 feature descriptors and use GA for feature selection. Three schemes are considered: weight optimization with a real coded chromosome GA, the selection for optimal feature descriptor subset with a binary one, the simultaneity of weight optimization and the selection for optimal feature descriptor subset with a bi-coded chromosome GA motivated by [16]. As we just want to investigate the methodology in feature selection, the fitness function takes into consideration k-nearest neighbor (k-NN) classification accuracy instead of SVM one, which is one of the best classification algorithm [17]. In the first scheme, k-NN classification accuracy is considered as the fitness function. In the others, the fitness function takes into consideration k-NN classification accuracy combining with the size of feature descriptor subset [18]. The experiments are performed over 2000 classified Corel images to validate the performance of the approaches. The remainder of the paper is organized as follows. Section 2 describes the MPEG-7 image feature descriptors and the extraction of low-level image feature vectors. Section 3 introduces k-nearest neighbor classifier. Section 4 discusses the designs of the real coded chromosome GA, the binary coded one and the bi-coded one in our approaches. Section 5 describes the method of image annotation in our approaches. Section 6 illustrates the experimental results and analysis. Our conclusions and future work are given in Section 7. 
