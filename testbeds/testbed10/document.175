Forecasting with artificial neural networks:: The state of the art

Guoqiang Zhang, B. Eddy Patuwo, Michael Y. Hu

1. Introduction
Recent research activities in artificial neural networks (ANNs) have shown that ANNs have powerful pattern classification and pattern recognition capabilities. Inspired by biological systems, particularly by research into the human brain, ANNs are able to learn from and generalize from experience. Currently, ANNs are being used for a wide variety of tasks in many different fields of business, industry and science (Widrow et al., 1994).

One major application area of ANNs is forecasting (Sharda, 1994). ANNs provide an attractive alternative tool for both forecasting researchers and practitioners. Several distinguishing features of ANNs make them valuable and attractive for a forecasting task. First, as opposed to the traditional model-based methods, ANNs are data-driven self-adaptive methods in that there are few a priori assumptions about the models for problems under study. They learn from examples and capture subtle functional relationships among the data even if the underlying relationships are unknown or hard to describe. Thus ANNs are well suited for problems whose solutions require knowledge that is difficult to specify but for which there are enough data or observations. In this sense they can be treated as one of the multivariate nonlinear nonparametric statistical methods (White, 1989, Ripley, 1993 and Cheng and Titterington, 1994). This modeling approach with the ability to learn from experience is very useful for many practical problems since it is often easier to have data than to have good theoretical guesses about the underlying laws governing the systems from which data are generated. The problem with the data-driven modeling approach is that the underlying rules are not always evident and observations are often masked by noise. It nevertheless provides a practical and, in some situations, the only feasible way to solve real-world problems.

Second, ANNs can generalize. After learning the data presented to them (a sample), ANNs can often correctly infer the unseen part of a population even if the sample data contain noisy information. As forecasting is performed via prediction of future behavior (the unseen part) from examples of past behavior, it is an ideal application area for neural networks, at least in principle.

Third, ANNs are universal functional approximators. It has been shown that a network can approximate any continuous function to any desired accuracy (Irie and Miyake, 1988, Hornik et al., 1989, Cybenko, 1989, Funahashi, 1989, Hornik, 1991 and Hornik, 1993). ANNs have more general and flexible functional forms than the traditional statistical methods can effectively deal with. Any forecasting model assumes that there exists an underlying (known or unknown) relationship between the inputs (the past values of the time series and/or other relevant variables) and the outputs (the future values). Frequently, traditional statistical forecasting models have limitations in estimating this underlying function due to the complexity of the real system. ANNs can be a good alternative method to identify this function.

Finally, ANNs are nonlinear. Forecasting has long been the domain of linear statistics. The traditional approaches to time series prediction, such as the Box-Jenkins or ARIMA method (Box and Jenkins, 1976 and Pankratz, 1983), assume that the time series under study are generated from linear processes. Linear models have advantages in that they can be understood and analyzed in great detail, and they are easy to explain and implement. However, they may be totally inappropriate if the underlying mechanism is nonlinear. It is unreasonable to assume a priori that a particular realization of a given time series is generated by a linear process. In fact, real world systems are often nonlinear (Granger and Terasvirta, 1993). During the last decade, several nonlinear time series models such as the bilinear model (Granger and Anderson, 1978), the threshold autoregressive (TAR) model (Tong and Lim, 1980), and the autoregressive conditional heteroscedastic (ARCH) model (Engle, 1982) have been developed. (See De Gooijer and Kumar (1992)for a review of this field.) However, these nonlinear models are still limited in that an explicit relationship for the data series at hand has to be hypothesized with little knowledge of the underlying law. In fact, the formulation of a nonlinear model to a particular data set is a very difficult task since there are too many possible nonlinear patterns and a prespecified nonlinear model may not be general enough to capture all the important features. Artificial neural networks, which are nonlinear data-driven approaches as opposed to the above model-based nonlinear methods, are capable of performing nonlinear modeling without a priori knowledge about the relationships between input and output variables. Thus they are a more general and flexible modeling tool for forecasting.

The idea of using ANNs for forecasting is not new. The first application dates back to 1964. Hu (1964), in his thesis, uses the Widrow's adaptive linear network to weather forecasting. Due to the lack of a training algorithm for general multi-layer networks at the time, the research was quite limited. It is not until 1986 when the backpropagation algorithm was introduced (Rumelhart et al., 1986b and Werbos, 1988) that there had been much development in the use of ANNs for forecasting. Werbos (1974), Werbos (1988)first formulates the backpropagation and finds that ANNs trained with backpropagation outperform the traditional statistical methods such as regression and Box-Jenkins approaches. Lapedes and Farber (1987)conduct a simulated study and conclude that ANNs can be used for modeling and forecasting nonlinear time series. Weigend et al., 1990, Weigend et al., 1992 and Cottrell et al., 1995address the issue of network structure for forecasting real-world time series. Tang et al. (1991), Sharda and Patil (1992), and Tang and Fishwick (1993), among others, report results of several forecasting comparisons between Box-Jenkins and ANN models. In a recent forecasting competition organized by Weigend and Gershenfeld (1993)through the Santa Fe Institute, winners of each set of data used ANN models (Gershenfeld and Weigend, 1993).

Research efforts on ANNs for forecasting are considerable. The literature is vast and growing. Marquez et al. (1992)and Hill et al. (1994)review the literature comparing ANNs with statistical models in time series forecasting and regression-based forecasting. However, their review focuses on the relative performance of ANNs and includes only a few papers. In this paper, we attempt to provide a more comprehensive review of the current status of research in this area. We will mainly focus on the neural network modeling issues. This review aims at serving two purposes. First, it provides a general summary of the work in ANN forecasting done to date. Second, it provides guidelines for neural network modeling and fruitful areas for future research.

The paper is organized as follows. In Section 2, we give a brief description of the general paradigms of the ANNs, especially those used for the forecasting purpose. Section 3describes a variety of the fields in which ANNs have been applied as well as the methodology used. Section 4discusses the key modeling issues of ANNs in forecasting. The relative performance of ANNs over traditional statistical methods is reported in Section 5. Finally, conclusions and directions of future research are discussed in Section 6.

2. An overview of ANNs
In this section we give a brief presentation of artificial neural networks. We will focus on a particular structure of ANNs, multi-layer feedforward networks, which is the most popular and widely-used network paradigm in many applications including forecasting. For a general introductory account of ANNs, readers are referred to Wasserman, 1989, Hertz et al., 1991 and Smith, 1993. Rumelhart et al., 1986a, Rumelhart et al., 1986b, Rumelhart et al., 1994, Rumelhart et al., 1995, Lippmann, 1987, Hinton, 1992 and Hammerstrom, 1993illustrate the basic ideas in ANNs. Also, a couple of general review papers are now available. Hush and Horne (1993)summarize some recent theoretical developments in ANNs since Lippmann (1987)tutorial article. Masson and Wang (1990)give a detailed description of five different network models. Wilson and Sharda (1992)present a review of applications of ANNs in the business setting. Sharda (1994)provides an application bibliography for researchers in Management Science/Operations Research. A bibliography of neural network business applications research is also given by Wong et al. (1995). Kuan and White (1994)review the ANN models used by economists and econometricians and establish several theoretical frames for ANN learning. Cheng and Titterington (1994)make a detailed analysis and comparison of ANNs paradigms with traditional statistical methods.

Artificial neural networks, originally developed to mimic basic biological neural systems– the human brain particularly, are composed of a number of interconnected simple processing elements called neurons or nodes. Each node receives an input signal which is the total “information” from other nodes or external stimuli, processes it locally through an activation or transfer function and produces a transformed output signal to other nodes or external outputs. Although each individual neuron implements its function rather slowly and imperfectly, collectively a network can perform a surprising number of tasks quite efficiently (Reilly and Cooper, 1990). This information processing characteristic makes ANNs a powerful computational device and able to learn from examples and then to generalize to examples never before seen.

Many different ANN models have been proposed since 1980s. Perhaps the most influential models are the multi-layer perceptrons (MLP), Hopfield networks, and Kohonen's self organizing networks. Hopfield (1982)proposes a recurrent neural network which works as an associative memory. An associative memory can recall an example from a partial or distorted version. Hopfield networks are non-layered with complete interconnectivity between nodes. The outputs of the network are not necessarily the functions of the inputs. Rather they are stable states of an iterative process. Kohonen's feature maps (Kohonen, 1982) are motivated by the self-organizing behavior of the human brain.

In this section and the rest of the paper, our focus will be on the multi-layer perceptrons. The MLP networks are used in a variety of problems especially in forecasting because of their inherent capability of arbitrary input–output mapping. Readers should be aware that other types of ANNs such as radial-basis functions networks (Park and Sandberg, 1991, Park and Sandberg, 1993 and Chng et al., 1996), ridge polynomial networks (Shin and Ghosh, 1995), and wavelet networks (Zhang and Benveniste, 1992 and Delyon et al., 1995) are also very useful in some applications due to their function approximating ability.

An MLP is typically composed of several layers of nodes. The first or the lowest layer is an input layer where external information is received. The last or the highest layer is an output layer where the problem solution is obtained. The input layer and output layer are separated by one or more intermediate layers called the hidden layers. The nodes in adjacent layers are usually fully connected by acyclic arcs from a lower layer to a higher layer. Fig. 1 gives an example of a fully connected MLP with one hidden layer.
