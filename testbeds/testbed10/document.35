Predictive models are used in a variety of medical domains for diagnostic and prognostic tasks. These models are built from ‘‘experience’’, which constitutes data acquired from actual cases. The data can be preprocessed and expressed in a set of rules, such as it is often the case in knowledge-based expert systems, or serve as training data for statistical and machine learning models. Among the options in the latter category, the most popular models in medicine are logistic regression (LR) and artificial neural networks (ANN). These models have their origins in two different communities (statistics and computer science), but share many similarities. In this article, we show that logistic regression and artificial neural networks share common roots in statistical pattern recognition, and how the latter model can be seen as a generalization of the former. We briefly compare these two methods with other popular classi- fication algorithms from the machine learning field, such as k-nearest neighbors, decision trees, and support vector machines. There are now several implementations of predictive modeling algorithms readily available, both as free and commercial software. The quality of the results obtained using these models mainly depends on three factors: the quality of the data set employed in model-building, the care with which adjustable model parameters were chosen, and the evaluation criteria used to report the results of the modeling process. It is imperative that these details be presented in papers using predictive modeling, as otherwise the validity of the claims in the papers cannot be assessed by the reader. We therefore analyze the model-building process of logistic regression and neural network models in some detail, and point out which factors need to be considered when judging research results using predictive models. To gauge the current state of reporting results in the literature, we sampled 72 papers comparing both logistic regression and neural network models on medical data sets. We analyzed these papers with respect to several criteria, such as size of data sets, model parameter selection scheme, and performance measure used in reporting model results.
