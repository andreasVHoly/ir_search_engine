Traditional intrusion prevention techniques, such as firewalls, access control or encryption, have failed to fully protect networks and systems from increasingly sophisticated attacks and malwares. As a result, intrusion detection systems (IDS) have become an indispensable component of security infrastructure to detect these threats before they inflict widespread damage. When building an IDS one needs to consider many issues, such as data collection, data pre-processing, intrusion recognition, reporting, and response. Among them, intrusion recognition is most vital. Audit data is compared with detection models, which describe the patterns of intrusive or benign behavior, so that both successful and unsuccessful intrusion attempts can be identified. Since Denning first proposed an intrusion detection model in 1987 [80], many research efforts have been focused on how to effectively and accurately construct detection models. Between the late 1980s and the early 1990s, a combination of expert systems and statistical approaches was very popular. Detection models were derived from the domain knowledge of security experts. From the mid-1990s to the late 1990s, acquiring knowledge of normal or abnormal behavior had turned from manual to automatic. Artificial intelligence and machine learning techniques were used to discover the underlying models from a set of training data. Commonly used methods were rule based induction, classification and data clustering. The process of automatically constructing models from data is not trivial, especially for intrusion detection problems. This is because intrusion detection faces problems such as huge network traffic volumes, highly imbalanced data distribution, the difficulty to realize decision boundaries between normal and abnormal behavior, and a requirement for continuous adaptation to a constantly changing environment. Artificial intelligence and machine learning have shown limitations in achieving high detection accuracy and fast processing times when confronted with these requirements. For example, the detection model in the winning entry of the KDD99 competition was composed of 50 10 C5 decision trees. The second-placed entry consisted of a decision forest with 755 trees [92]. Fortunately, computational intelligence techniques, known for their ability to adapt and to exhibit fault tolerance, high computational speed and resilience against noisy information, compensate for the limitations of these two approaches. The aim of this review is twofold: the first is to present a comprehensive survey on research contributions that investigate utilization of computational intelligence (CI) methods in building intrusion detection models; the second aim is to define existing research challenges, and to highlight promising new research directions. The scope of the survey is the core methods of CI, which encompass artificial neural networks, fuzzy sets, evolutionary computation methods, artificial immune systems, swarm intelligence and soft computing. Soft computing, unlike the rest of the methods, has the synergistic power to intertwine the pros of these methods in such a way that their cons will be compensated. Therefore, it is an indispensable component in CI. The remainder of this review is organized as follows. Section 2 defines IDSs and computation intelligence. Section 3 introduces commonly used datasets and performance evaluation measures, with the purpose of removing the confusion found in some research work. Section 4 categorizes, compares and summarizes core methods in CI that have been proposed to solve intrusion detection problems. Section 5 compares the strengths and limitations of these approaches, and identifies future research trends and challenges. Section 6 concludes. An intrusion detection system dynamically monitors the events taking place in a system, and decides whether these events are symptomatic of an attack or constitute a legitimate use of the system [77]. Fig. 1 depicts the organization of an IDS where solid lines indicate data/control flow, while dashed lines indicate responses to intrusive activities. In general, IDSs fall into two categories according to the detection methods they employ, namely (i) misuse detection and (ii) anomaly detection. Misuse detection identifies intrusions by matching observed data with pre-defined descriptions of intrusive behavior. Therefore, well-known intrusions can be detected efficiently with a very low false alarm rate. For this reason, the approach is widely adopted in the majority of commercial systems. However, intrusions are usually polymorph, and evolve continuously. Misuse detection will fail easily when facing unknown intrusions. One way to address this problem is to regularly update the knowledge base, either manually which is time consuming and laborious, or automatically with the help of supervised learning algorithms. Unfortunately, datasets for this purpose are usually expensive to prepare, as they require labeling of each instance in the dataset as normal or a type of intrusion. Another way to address this problem is to follow the anomaly detection model proposed by Denning [80]. Anomaly detection is orthogonal to misuse detection. It hypothesizes that abnormal behavior is rare and different from normal behavior. Hence, it builds models for normal behavior and detects anomaly in observed data by noticing deviations from these models. There are two types of anomaly detection [54]. The first is static anomaly detection, which assumes that the behavior of monitored targets never changes, such as system call sequences of an Apache service. The second type is dynamic anomaly detection. It extracts patterns from behavioral habits of end users, or usage history of networks/hosts. Sometimes these patterns are called profiles. Clearly, anomaly detection has the capability of detecting new types of intrusions, and only requires normal data when building profiles. However, its major difficulty lies in discovering boundaries between normal and abnormal behavior, due to the deficiency of abnormal samples in the training phase. Another difficulty is to adapt to constantly changing normal behavior, especially for dynamic anomaly detection. In addition to the detection method, there are other characteristics one can use to classify IDSs, as shown in Fig. 2. .2. Computational intelligence Computational intelligence (CI) is a fairly new research field with competing definitions. For example, in Computational Intelligence—A Logical Approach [241], the authors defined CI as: Computational Intelligence is the study of the design of intelligent agents.... An intelligent agent is a system that acts intelligently: What it does is appropriate for its circumstances and its goal, it is flexible to changing environments and changing goals, it learns from experience, and it makes appropriate choices given perceptual limitations and finite computation. In contrast, Bezdek [39] defined CI as: A system is computational intelligent when it: deals with only numerical (low-level) data, has pattern recognition components, does not use knowledge in the artificial intelligence sense; and additionally when it (begins to) exhibit (i) computational adaptivity, (ii) computational fault tolerance, (iii) speed approaching human-like turnaround, and (iv) error rates that approximate human performance. The discussion in [63,89] further confirm the characteristics of computational intelligence systems summarized by Bezdek’s definition. Therefore, in this review, we subscribe to Bezdek’s definition. CI is different from the well-known field of artificial intelligence (AI). AI handles symbolic knowledge representation, while CI handles numeric representation of information; AI concerns itself with high-level cognitive functions, while CI is concerned with low-level cognitive functions. Furthermore, AI analyzes the structure of a given problem and attempts to construct an intelligent system based upon this structure, thus operating in a top-down manner, while the structure is expected to emerge from an unordered beginning in CI, thus operating in a bottom-up manner [63,89].
