An application of support vector machines in bankruptcy prediction model

Kyung-Shik Shin, , Taik Soo Lee1, , Hyun-jung Kim2, 

1. Introduction
The development of the bankruptcy prediction model has long been regarded as an important and widely studied issue in the academic and business community. The bankrupty prediction can have significant impact on lending decisions and profitability of financial institutions.

Our research pertains to a bankruptcy prediction model that can provide a basis for credit rating system. Early studies of bankruptcy prediction used statistical techniques such as multiple discriminant analysis (MDA) (Altman, 1968 and Altman, 1983), logit (Ohlson, 1980) and probit (Zmijewski, 1984). Recently, however, numerous studies have demonstrated that artificial intelligence such as neural networks (NNs) can be an alternative method for classification problems to which traditional statistical method have long been applied (Atiya, 2001, Barniv et al., 1997, Bell, 1997, Boritz and Kennedy, 1995, Charalambous et al., 2000, Etheridge and Sriram, 1997, Fletcher and Goss, 1993, Grice and Dugan, 2001, Jo et al., 1997, Lee et al., 1996, Leshno and Spector, 1996, Odom and Sharda, 1990, Salchenberger et al., 1992, Shin and Han, 1998, Tam and Kiang, 1992, Wilson and Sharda, 1994 and Zhang et al., 1999).

Although numerous theoretical and experimental studies reported the usefulness of the back-propagation neural network (BPN) in classification studies, there are several limitations in building the model. First, it is an art to find an appropriate NN model, which can reflect problem characteristics because there are large numbers of controlling parameters and processing elements in the layer. Second, the gradient descent search process to compute the synaptic weights may converge to a local minimum solution that is a good fit for the training examples. Finally, the empirical risk minimization principle that seeks to minimize the training error does not guarantee good generalization performance. To determine the size of the training set is also the main issue to be resolved in the generalization because the sufficiency and efficiency of the training set is one most commonly influenced factor.

This study investigates the effectiveness of support vector machines (SVM) approach in detecting the underlying data pattern for the corporate failure prediction tasks. SVM classification exercise finds hyperplanes in the possible space for maximizing the distance from the hyperplane to the data points, which is equivalent to solving a quadratic optimization problem. The solution of strictly convex problems for SVM is unique and global. SVM implement the structural risk minimization (SRM) principle that is known to have high generalization performance. As the complexity increases by numbers of support vectors, SVM is constructed through trading off decreasing the number of training errors and increasing the risk of overfitting the data. However, a data-dependent SRM for SVM does not rigorously support the argument that good generalization performance of SVM is attributable to SRM (Burges, 1998). Since SVM captures geometric characteristics of feature space without deriving weights of networks from the training data, it is capable of extracting the optimal solution with the small training set size.

While there are several arguments that support the observed high accuracy of SVM, as the training set size is getting smaller, the preliminary results show that the accuracy and generalization performance of SVM is better than that of the standard BPN. In addition, since choosing an appropriate value for parameters of SVM plays an important role on the performance of SVM, we also investigate the effect of the variability in prediction and generalization performance of SVM with respect to various values of parameters in SVM such as the upper bound C and the bandwidth of the kernel function according to the size of the training set.

The remainder of this paper is organized as follows. Section 2 provides a description of artificial intelligence applications for the bankruptcy prediction modeling, including a review of prior studies relevant to the research topic of this paper. Section 3 provides a brief description of SVM and demonstrates the several superior points of the SVM algorithm compared with BPN. Section 4 describes the research data and experiments. Section 5 summarizes and analyzes empirical results. Section 6 discusses the conclusions and future research issues.

6. Conclusions
In this study, we show that the proposed classifier of SVM approach outperforms BPN to the problem of corporate bankruptcy prediction. Our experimentation results demonstrate that SVM has the highest level of accuracies and better generalization performance than BPN as the training set size is getting smaller sets. We also examine the effect of various values of parameters in SVM such as the upper bound C and the bandwidth of the kernel function. In addition, we investigate and summarize the several superior points of the SVM algorithm compared with BPN.

Our study has the following limitations that need further research. First, in SVM, the choice of the kernel function and the determination of optimal values of the parameters have a critical impact on the performance of the resulting system. We also need to investigate to develop a structured method of selecting an optimal value of parameters in SVM for the best prediction performance as well as the effect of other factor that is fixed in the above experiment such as the kernel function. The second issue for future research relates to the generalization of SVM on the basis of the appropriate level of the training set size and gives a guideline to measure the generalization performance.
